{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint: tliu/helmholtz_isotropic_1.0/model-3vweeuk1:best\n",
      "kept model-3vweeuk1:v17, ['best', 'latest']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-3vweeuk1:best, 192.42MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.9\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "PytorchStreamReader failed reading file data/2: invalid header or archive is corrupted",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 106\u001b[0m\n\u001b[1;32m    101\u001b[0m artifact_dir \u001b[39m=\u001b[39m WandbLogger\u001b[39m.\u001b[39mdownload_artifact(\n\u001b[1;32m    102\u001b[0m   artifact\u001b[39m=\u001b[39mcheckpoint_reference,\n\u001b[1;32m    103\u001b[0m   save_dir\u001b[39m=\u001b[39mwavebench_checkpoint_path)\n\u001b[1;32m    105\u001b[0m \u001b[39m# load checkpoint\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m model \u001b[39m=\u001b[39m LitModel\u001b[39m.\u001b[39;49mload_from_checkpoint(\n\u001b[1;32m    107\u001b[0m   Path(artifact_dir) \u001b[39m/\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mmodel.ckpt\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    109\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mmodel hparams:\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    110\u001b[0m pp\u001b[39m.\u001b[39mpprint(model\u001b[39m.\u001b[39mhparams\u001b[39m.\u001b[39mmodel_config)\n",
      "File \u001b[0;32m~/anaconda3/envs/ffcv/lib/python3.9/site-packages/pytorch_lightning/core/module.py:1531\u001b[0m, in \u001b[0;36mLightningModule.load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m   1452\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_from_checkpoint\u001b[39m(\n\u001b[1;32m   1453\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1458\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m   1459\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Self:\n\u001b[1;32m   1460\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1461\u001b[0m \u001b[39m    Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint\u001b[39;00m\n\u001b[1;32m   1462\u001b[0m \u001b[39m    it stores the arguments passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1529\u001b[0m \u001b[39m        y_hat = pretrained_model(x)\u001b[39;00m\n\u001b[1;32m   1530\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1531\u001b[0m     loaded \u001b[39m=\u001b[39m _load_from_checkpoint(\n\u001b[1;32m   1532\u001b[0m         \u001b[39mcls\u001b[39;49m,\n\u001b[1;32m   1533\u001b[0m         checkpoint_path,\n\u001b[1;32m   1534\u001b[0m         map_location,\n\u001b[1;32m   1535\u001b[0m         hparams_file,\n\u001b[1;32m   1536\u001b[0m         strict,\n\u001b[1;32m   1537\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   1538\u001b[0m     )\n\u001b[1;32m   1539\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(Self, loaded)\n",
      "File \u001b[0;32m~/anaconda3/envs/ffcv/lib/python3.9/site-packages/pytorch_lightning/core/saving.py:60\u001b[0m, in \u001b[0;36m_load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_load_from_checkpoint\u001b[39m(\n\u001b[1;32m     52\u001b[0m     \u001b[39mcls\u001b[39m: Union[Type[\u001b[39m\"\u001b[39m\u001b[39mpl.LightningModule\u001b[39m\u001b[39m\"\u001b[39m], Type[\u001b[39m\"\u001b[39m\u001b[39mpl.LightningDataModule\u001b[39m\u001b[39m\"\u001b[39m]],\n\u001b[1;32m     53\u001b[0m     checkpoint_path: Union[_PATH, IO],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m     58\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[\u001b[39m\"\u001b[39m\u001b[39mpl.LightningModule\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mpl.LightningDataModule\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m     59\u001b[0m     \u001b[39mwith\u001b[39;00m pl_legacy_patch():\n\u001b[0;32m---> 60\u001b[0m         checkpoint \u001b[39m=\u001b[39m pl_load(checkpoint_path, map_location\u001b[39m=\u001b[39;49mmap_location)\n\u001b[1;32m     62\u001b[0m     \u001b[39m# convert legacy checkpoints to the new format\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     checkpoint \u001b[39m=\u001b[39m _pl_migrate_checkpoint(\n\u001b[1;32m     64\u001b[0m         checkpoint, checkpoint_path\u001b[39m=\u001b[39m(checkpoint_path \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(checkpoint_path, (\u001b[39mstr\u001b[39m, Path)) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m     65\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/ffcv/lib/python3.9/site-packages/lightning_fabric/utilities/cloud_io.py:51\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(path_or_url, map_location)\u001b[0m\n\u001b[1;32m     49\u001b[0m fs \u001b[39m=\u001b[39m get_filesystem(path_or_url)\n\u001b[1;32m     50\u001b[0m \u001b[39mwith\u001b[39;00m fs\u001b[39m.\u001b[39mopen(path_or_url, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mload(f, map_location\u001b[39m=\u001b[39;49mmap_location)\n",
      "File \u001b[0;32m~/anaconda3/envs/ffcv/lib/python3.9/site-packages/torch/serialization.py:809\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    808\u001b[0m                 \u001b[39mraise\u001b[39;00m pickle\u001b[39m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 809\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n\u001b[1;32m    810\u001b[0m \u001b[39mif\u001b[39;00m weights_only:\n\u001b[1;32m    811\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/ffcv/lib/python3.9/site-packages/torch/serialization.py:1172\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1170\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(data_file, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1171\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[0;32m-> 1172\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m   1174\u001b[0m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1176\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/ffcv/lib/python3.9/pickle.py:1212\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1210\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mEOFError\u001b[39;00m\n\u001b[1;32m   1211\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(key, bytes_types)\n\u001b[0;32m-> 1212\u001b[0m         dispatch[key[\u001b[39m0\u001b[39;49m]](\u001b[39mself\u001b[39;49m)\n\u001b[1;32m   1213\u001b[0m \u001b[39mexcept\u001b[39;00m _Stop \u001b[39mas\u001b[39;00m stopinst:\n\u001b[1;32m   1214\u001b[0m     \u001b[39mreturn\u001b[39;00m stopinst\u001b[39m.\u001b[39mvalue\n",
      "File \u001b[0;32m~/anaconda3/envs/ffcv/lib/python3.9/pickle.py:1253\u001b[0m, in \u001b[0;36m_Unpickler.load_binpersid\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1251\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_binpersid\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1252\u001b[0m     pid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstack\u001b[39m.\u001b[39mpop()\n\u001b[0;32m-> 1253\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpersistent_load(pid))\n",
      "File \u001b[0;32m~/anaconda3/envs/ffcv/lib/python3.9/site-packages/torch/serialization.py:1142\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1141\u001b[0m     nbytes \u001b[39m=\u001b[39m numel \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1142\u001b[0m     typed_storage \u001b[39m=\u001b[39m load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n\u001b[1;32m   1144\u001b[0m \u001b[39mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m~/anaconda3/envs/ffcv/lib/python3.9/site-packages/torch/serialization.py:1112\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1109\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_tensor\u001b[39m(dtype, numel, key, location):\n\u001b[1;32m   1110\u001b[0m     name \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdata/\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m-> 1112\u001b[0m     storage \u001b[39m=\u001b[39m zip_file\u001b[39m.\u001b[39;49mget_storage_from_record(name, numel, torch\u001b[39m.\u001b[39;49mUntypedStorage)\u001b[39m.\u001b[39m_typed_storage()\u001b[39m.\u001b[39m_untyped_storage\n\u001b[1;32m   1113\u001b[0m     \u001b[39m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1114\u001b[0m     \u001b[39m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m     typed_storage \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstorage\u001b[39m.\u001b[39mTypedStorage(\n\u001b[1;32m   1116\u001b[0m         wrap_storage\u001b[39m=\u001b[39mrestore_location(storage, location),\n\u001b[1;32m   1117\u001b[0m         dtype\u001b[39m=\u001b[39mdtype,\n\u001b[1;32m   1118\u001b[0m         _internal\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: PytorchStreamReader failed reading file data/2: invalid header or archive is corrupted"
     ]
    }
   ],
   "source": [
    "\"\"\" Evaluate all models on the time-harmonic datasets\"\"\"\n",
    "import pprint\n",
    "from pathlib import Path\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "import ml_collections\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import os\n",
    "from matplotlib import colors\n",
    "import torch\n",
    "from wavebench.dataloaders.helmholtz_loader import get_dataloaders_helmholtz\n",
    "\n",
    "\n",
    "from wavebench import wavebench_figure_path\n",
    "from wavebench.nn.pl_model_wrapper import LitModel\n",
    "from wavebench import wavebench_checkpoint_path\n",
    "from wavebench.plot_utils import plot_images, remove_frame\n",
    "\n",
    "\n",
    "\n",
    "all_models = [\n",
    "  {\n",
    "    \"tag\": 'fno-depth-4',\n",
    "    \"config.model_config/model_name\": 'fno',\n",
    "    \"config.model_config/num_hidden_layers\": 4\n",
    "  },\n",
    "  {\n",
    "    \"tag\": 'fno-depth-8',\n",
    "    \"config.model_config/model_name\": 'fno',\n",
    "    \"config.model_config/num_hidden_layers\": 8\n",
    "  },\n",
    "  {\n",
    "    \"tag\": 'unet-ch-32',\n",
    "    \"config.model_config/model_name\": 'unet',\n",
    "    \"config.model_config/channel_reduction_factor\": 2\n",
    "  },\n",
    "  {\n",
    "    \"tag\": 'unet-ch-64',\n",
    "    \"config.model_config/model_name\": 'unet',\n",
    "    \"config.model_config/channel_reduction_factor\": 1\n",
    "  },\n",
    "\n",
    "              ]\n",
    "\n",
    "\n",
    "# Initialize the W&B API client\n",
    "api = wandb.Api()\n",
    "\n",
    "\n",
    "pp = pprint.PrettyPrinter(depth=6)\n",
    "device = 'cpu'\n",
    "\n",
    "eval_config = ml_collections.ConfigDict()\n",
    "\n",
    "\n",
    "# problem setting: can be 'isotropic' or 'anisotropic'\n",
    "for eval_config.kernel_type in ['isotropic', 'anisotropic']:\n",
    "\n",
    "  # frequency: can be in [1.0, 1.5, 2.0, 4.0]\n",
    "  # for eval_config.frequency in [4.0]:\n",
    "  for eval_config.frequency in [1.0, 1.5, 2.0, 4.0]:\n",
    "    save_path = f\"{wavebench_figure_path}/time_harmonic/model_out_{eval_config.kernel_type}_{eval_config.frequency}\"\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "      os.makedirs(save_path)\n",
    "\n",
    "    test_loader = get_dataloaders_helmholtz(\n",
    "      eval_config.kernel_type,\n",
    "      eval_config.frequency)['test']\n",
    "    model_dict = {}\n",
    "\n",
    "    for model_filters in all_models:\n",
    "      _model_filters = model_filters.copy()\n",
    "\n",
    "      model_tag = _model_filters.pop('tag')\n",
    "\n",
    "      project = f'helmholtz_{eval_config.kernel_type}_{eval_config.frequency}'\n",
    "      runs = api.runs(\n",
    "        path=f\"tliu/{project}\",\n",
    "        filters=_model_filters)\n",
    "\n",
    "      # make sure that there is a unique model that satisfies the filters\n",
    "      assert len(runs) == 1\n",
    "\n",
    "      run_id = runs[0].id\n",
    "\n",
    "      checkpoint_reference = f\"tliu/{project}/model-{run_id}:best\"\n",
    "      print(f'checkpoint: {checkpoint_reference}')\n",
    "\n",
    "      # delete all the checkpoints that do not have the aliases such as 'best\n",
    "      artifact_versions = api.artifact_versions(\n",
    "        name=f'{project}/model-{run_id}', type_name='model')\n",
    "\n",
    "      for v in artifact_versions:\n",
    "        if len(v.aliases) == 0:\n",
    "          v.delete()\n",
    "          print(f'deleted {v.name}')\n",
    "        else:\n",
    "          print(f'kept {v.name}, {v.aliases}')\n",
    "\n",
    "      artifact_dir = WandbLogger.download_artifact(\n",
    "        artifact=checkpoint_reference,\n",
    "        save_dir=wavebench_checkpoint_path)\n",
    "\n",
    "      # load checkpoint\n",
    "      model = LitModel.load_from_checkpoint(\n",
    "        Path(artifact_dir) / \"model.ckpt\").to(device)\n",
    "\n",
    "      print('model hparams:')\n",
    "      pp.pprint(model.hparams.model_config)\n",
    "\n",
    "      model_dict[model_tag] = model\n",
    "\n",
    "    sample_input, sample_target = next(iter(test_loader))\n",
    "\n",
    "\n",
    "    # plot the ground-truth data\n",
    "    fig, axes = plot_images(\n",
    "      [sample_input.squeeze(),\n",
    "       sample_target.squeeze()[0],\n",
    "       sample_target.squeeze()[1]],\n",
    "      cbar='none',\n",
    "      vrange='individual',\n",
    "      fig_size=(9, 3),\n",
    "      shrink=0.5,\n",
    "      pad=0.02,\n",
    "      cmap='coolwarm')\n",
    "\n",
    "    axes[0].set_title('input')\n",
    "    axes[1].set_title('target real')\n",
    "    axes[2].set_title('target img')\n",
    "    [remove_frame(ax) for ax in axes.flatten()]\n",
    "\n",
    "    plt.suptitle(\n",
    "      f'Ground truth. Wavespeed: {eval_config.kernel_type}, Freq: {eval_config.frequency}',\n",
    "      y=0.98,\n",
    "      )\n",
    "\n",
    "    plt.savefig(\n",
    "      f\"{save_path}/ground_truth.pdf\",\n",
    "      format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "\n",
    "    # plot the predictions\n",
    "    pred_dict_real = {}\n",
    "\n",
    "    pred_dict_img = {}\n",
    "\n",
    "    for tag, model in model_dict.items():\n",
    "      pred = model(\n",
    "        sample_input.to(device)).detach().cpu().squeeze()\n",
    "      pred_dict_real[tag] = pred.squeeze()[0]\n",
    "      pred_dict_img[tag] = pred.squeeze()[1]\n",
    "\n",
    "    fig, axes = plot_images(\n",
    "      list(pred_dict_real.values()),\n",
    "      cbar='one',\n",
    "      fig_size=(9, 3),\n",
    "      shrink=0.5,\n",
    "      pad=0.02,\n",
    "      cmap='coolwarm')\n",
    "\n",
    "    plt.suptitle(\n",
    "      f'Predictions (real part). Wavespeed: {eval_config.kernel_type}, Freq: {eval_config.frequency}',\n",
    "      y=0.9,\n",
    "      )\n",
    "\n",
    "    for i, ax in enumerate(axes.flatten()):\n",
    "      ax.set_title( list(pred_dict_real.keys()) [i])\n",
    "      remove_frame(ax)\n",
    "\n",
    "    plt.savefig(\n",
    "      f\"{save_path}/real_pred.pdf\",\n",
    "      format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "    fig, axes = plot_images(\n",
    "      list(pred_dict_img.values()),\n",
    "      cbar='one',\n",
    "      fig_size=(9, 3),\n",
    "      shrink=0.5,\n",
    "      pad=0.02,\n",
    "      cmap='coolwarm')\n",
    "\n",
    "    plt.suptitle(\n",
    "      f'Prediction of the img part. Wavespeed: {eval_config.kernel_type}, Freq: {eval_config.frequency}',\n",
    "      y=0.9,\n",
    "      )\n",
    "\n",
    "    for i, ax in enumerate(axes.flatten()):\n",
    "      ax.set_title( list(pred_dict_img.keys()) [i])\n",
    "      remove_frame(ax)\n",
    "\n",
    "    plt.savefig(\n",
    "      f\"{save_path}/img_pred.pdf\",\n",
    "      format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "\n",
    "    pred_diff_dict_real = {}\n",
    "    pred_diff_dict_img = {}\n",
    "    # plot the error residual\n",
    "    for tag, model in model_dict.items():\n",
    "      pred = model(\n",
    "        sample_input.to(device)).detach().cpu().squeeze()\n",
    "      pred_diff_dict_real[f'{tag}_diff'] = ((\n",
    "        pred.squeeze()[0] - sample_target.squeeze()[0]).abs() / sample_target.squeeze().norm())\n",
    "      pred_diff_dict_img[f'{tag}_diff'] = ((\n",
    "        pred.squeeze()[1] - sample_target.squeeze()[1]).abs() / sample_target.squeeze().norm())\n",
    "\n",
    "\n",
    "    fig, axes = plot_images(\n",
    "      list(pred_diff_dict_real.values()),\n",
    "      cbar='one',\n",
    "      fig_size=(9, 3),\n",
    "      shrink=0.5,\n",
    "      pad=0.02,\n",
    "      cmap='Reds')\n",
    "\n",
    "    # axes[0,0]\n",
    "    for i, ax in enumerate(axes.flatten()):\n",
    "      ax.set_title( list(pred_diff_dict_real.keys()) [i])\n",
    "      remove_frame(ax)\n",
    "\n",
    "    plt.suptitle(\n",
    "      f'Real part diff Wavespeed: {eval_config.kernel_type}, Freq: {eval_config.frequency}',\n",
    "      y=0.9,\n",
    "      )\n",
    "\n",
    "    plt.savefig(\n",
    "      f\"{save_path}/real_part_diff.pdf\",\n",
    "      format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "\n",
    "    fig, axes = plot_images(\n",
    "      list(pred_diff_dict_img.values()),\n",
    "      cbar='one',\n",
    "      fig_size=(9, 3),\n",
    "      shrink=0.5,\n",
    "      pad=0.02,\n",
    "      cmap='Reds')\n",
    "\n",
    "    # axes[0,0]\n",
    "    for i, ax in enumerate(axes.flatten()):\n",
    "      ax.set_title( list(pred_diff_dict_img.keys()) [i])\n",
    "      remove_frame(ax)\n",
    "\n",
    "    plt.suptitle(\n",
    "      f'Img part diff Wavespeed: {eval_config.kernel_type}, Freq: {eval_config.frequency}',\n",
    "      y=0.9,\n",
    "      )\n",
    "\n",
    "    plt.savefig(\n",
    "      f\"{save_path}/img_part_diff.pdf\",\n",
    "      format=\"pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wave",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
