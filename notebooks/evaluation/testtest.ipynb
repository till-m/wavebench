{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint: tliu/helmholtz_isotropic_1.0/model-3vweeuk1:best\n",
      "kept model-3vweeuk1:v17, ['best', 'latest']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-3vweeuk1:best, 192.42MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model hparams:\n",
      "{'hidden_width': 64,\n",
      " 'model_name': 'fno',\n",
      " 'modes1': 16,\n",
      " 'modes2': 16,\n",
      " 'num_hidden_layers': 4,\n",
      " 'num_in_channels': 1,\n",
      " 'num_out_channels': 2}\n",
      "checkpoint: tliu/helmholtz_isotropic_1.0/model-5t7k78me:best\n",
      "kept model-5t7k78me:v14, ['best', 'latest']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-5t7k78me:best, 384.63MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model hparams:\n",
      "{'hidden_width': 64,\n",
      " 'model_name': 'fno',\n",
      " 'modes1': 16,\n",
      " 'modes2': 16,\n",
      " 'num_hidden_layers': 8,\n",
      " 'num_in_channels': 1,\n",
      " 'num_out_channels': 2}\n",
      "checkpoint: tliu/helmholtz_isotropic_1.0/model-n3fcxet4:best\n",
      "kept model-n3fcxet4:v17, ['latest', 'best']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-n3fcxet4:best, 88.95MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model hparams:\n",
      "{'channel_reduction_factor': 2,\n",
      " 'model_name': 'unet',\n",
      " 'n_input_channels': 1,\n",
      " 'n_output_channels': 2}\n",
      "checkpoint: tliu/helmholtz_isotropic_1.0/model-2rwsput0:best\n",
      "kept model-2rwsput0:v15, ['latest', 'best']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-2rwsput0:best, 355.33MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model hparams:\n",
      "{'channel_reduction_factor': 1,\n",
      " 'model_name': 'unet',\n",
      " 'n_input_channels': 1,\n",
      " 'n_output_channels': 2}\n",
      "checkpoint: tliu/helmholtz_isotropic_1.5/model-o0nu3wfx:best\n",
      "kept model-o0nu3wfx:v18, ['best', 'latest']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-o0nu3wfx:best, 192.42MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model hparams:\n",
      "{'hidden_width': 64,\n",
      " 'model_name': 'fno',\n",
      " 'modes1': 16,\n",
      " 'modes2': 16,\n",
      " 'num_hidden_layers': 4,\n",
      " 'num_in_channels': 1,\n",
      " 'num_out_channels': 2}\n",
      "checkpoint: tliu/helmholtz_isotropic_1.5/model-nokxpxbp:best\n",
      "kept model-nokxpxbp:v18, ['latest', 'best']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-nokxpxbp:best, 384.63MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model hparams:\n",
      "{'hidden_width': 64,\n",
      " 'model_name': 'fno',\n",
      " 'modes1': 16,\n",
      " 'modes2': 16,\n",
      " 'num_hidden_layers': 8,\n",
      " 'num_in_channels': 1,\n",
      " 'num_out_channels': 2}\n",
      "checkpoint: tliu/helmholtz_isotropic_1.5/model-g87y9gqj:best\n",
      "kept model-g87y9gqj:v17, ['latest', 'best']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-g87y9gqj:best, 88.95MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model hparams:\n",
      "{'channel_reduction_factor': 2,\n",
      " 'model_name': 'unet',\n",
      " 'n_input_channels': 1,\n",
      " 'n_output_channels': 2}\n",
      "checkpoint: tliu/helmholtz_isotropic_1.5/model-mth5y8ke:best\n",
      "kept model-mth5y8ke:v18, ['best', 'latest']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-mth5y8ke:best, 355.33MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model hparams:\n",
      "{'channel_reduction_factor': 1,\n",
      " 'model_name': 'unet',\n",
      " 'n_input_channels': 1,\n",
      " 'n_output_channels': 2}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 70\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(save_path):\n\u001b[1;32m     68\u001b[0m   os\u001b[39m.\u001b[39mmakedirs(save_path)\n\u001b[0;32m---> 70\u001b[0m test_loader \u001b[39m=\u001b[39m get_dataloaders_helmholtz(\n\u001b[1;32m     71\u001b[0m   eval_config\u001b[39m.\u001b[39;49mkernel_type,\n\u001b[1;32m     72\u001b[0m   eval_config\u001b[39m.\u001b[39;49mfrequency)[\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     73\u001b[0m model_dict \u001b[39m=\u001b[39m {}\n\u001b[1;32m     75\u001b[0m \u001b[39mfor\u001b[39;00m model_filters \u001b[39min\u001b[39;00m all_models:\n",
      "File \u001b[0;32m~/Desktop/projects/wavebench/wavebench/dataloaders/helmholtz_loader.py:154\u001b[0m, in \u001b[0;36mget_dataloaders_helmholtz\u001b[0;34m(kernel_type, frequency, train_batch_size, eval_batch_size, num_train_samples, num_val_samples, num_test_samples, sidelen, num_workers, use_ffcv)\u001b[0m\n\u001b[1;32m    142\u001b[0m   dataloaders \u001b[39m=\u001b[39m {\n\u001b[1;32m    143\u001b[0m     x: Loader(\n\u001b[1;32m    144\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mwavebench_dataset_path\u001b[39m}\u001b[39;00m\u001b[39m/time_harmonic/\u001b[39m\u001b[39m{\u001b[39;00mkernel_type\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mfrequency\u001b[39m}\u001b[39;00m\u001b[39m.beton\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    151\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m'\u001b[39m: [NDArrayDecoder(), ToTensor()]},\n\u001b[1;32m    152\u001b[0m       ) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m]}\n\u001b[1;32m    153\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m   dataset \u001b[39m=\u001b[39m HelmholtzDataset(\n\u001b[1;32m    155\u001b[0m       kernel_type\u001b[39m=\u001b[39;49mkernel_type,\n\u001b[1;32m    156\u001b[0m       frequency\u001b[39m=\u001b[39;49mfrequency,\n\u001b[1;32m    157\u001b[0m       )\n\u001b[1;32m    159\u001b[0m   subsets \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mrandom_split(\n\u001b[1;32m    160\u001b[0m       dataset, [num_train_samples, num_val_samples, num_test_samples],\n\u001b[1;32m    161\u001b[0m       generator\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mGenerator()\u001b[39m.\u001b[39mmanual_seed(\u001b[39m42\u001b[39m))\n\u001b[1;32m    163\u001b[0m   image_datasets \u001b[39m=\u001b[39m {\n\u001b[1;32m    164\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m: subsets[\u001b[39m0\u001b[39m],\n\u001b[1;32m    165\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m: subsets[\u001b[39m1\u001b[39m],\n\u001b[1;32m    166\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m: subsets[\u001b[39m2\u001b[39m]}\n",
      "File \u001b[0;32m~/Desktop/projects/wavebench/wavebench/dataloaders/helmholtz_loader.py:39\u001b[0m, in \u001b[0;36mHelmholtzDataset.__init__\u001b[0;34m(self, kernel_type, frequency)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39mfor\u001b[39;00m path \u001b[39min\u001b[39;00m absolute_file_paths(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mhelmholtz_dataset_path\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mkernel_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m):\n\u001b[1;32m     37\u001b[0m   \u001b[39mif\u001b[39;00m path\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39mdata-set_wavefield\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m     38\u001b[0m     pressure_paths\u001b[39m.\u001b[39mappend(\n\u001b[0;32m---> 39\u001b[0m         get_files_with_extension(path, \u001b[39m'\u001b[39;49m\u001b[39mH@\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m     41\u001b[0m \u001b[39mif\u001b[39;00m frequency \u001b[39m==\u001b[39m \u001b[39m1.0\u001b[39m:\n\u001b[1;32m     42\u001b[0m   pressure_with_frequency \u001b[39m=\u001b[39m [a \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m flatten_list(pressure_paths)\\\n\u001b[1;32m     43\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m1.00000E+01Hz\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m a\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]]\n",
      "File \u001b[0;32m~/Desktop/projects/wavebench/wavebench/utils.py:41\u001b[0m, in \u001b[0;36mget_files_with_extension\u001b[0;34m(folder_path, extension)\u001b[0m\n\u001b[1;32m     38\u001b[0m       search_files(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(root, directory))\n\u001b[1;32m     40\u001b[0m \u001b[39m# Start searching files from the provided folder path\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m search_files(folder_path)\n\u001b[1;32m     42\u001b[0m \u001b[39mreturn\u001b[39;00m file_paths\n",
      "File \u001b[0;32m~/Desktop/projects/wavebench/wavebench/utils.py:38\u001b[0m, in \u001b[0;36mget_files_with_extension.<locals>.search_files\u001b[0;34m(current_folder)\u001b[0m\n\u001b[1;32m     34\u001b[0m     file_paths\u001b[39m.\u001b[39madd(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mnormpath(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(root, file)))\n\u001b[1;32m     36\u001b[0m \u001b[39mfor\u001b[39;00m directory \u001b[39min\u001b[39;00m dirs:\n\u001b[1;32m     37\u001b[0m   \u001b[39m# Recursively search for files in subfolders\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m   search_files(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(root, directory))\n",
      "File \u001b[0;32m~/Desktop/projects/wavebench/wavebench/utils.py:34\u001b[0m, in \u001b[0;36mget_files_with_extension.<locals>.search_files\u001b[0;34m(current_folder)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m files:\n\u001b[1;32m     31\u001b[0m   \u001b[39m# Check if the file has the desired extension\u001b[39;00m\n\u001b[1;32m     32\u001b[0m   \u001b[39mif\u001b[39;00m file\u001b[39m.\u001b[39mendswith(extension):\n\u001b[1;32m     33\u001b[0m     \u001b[39m# Append the normalized absolute path of the file to the set\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m     file_paths\u001b[39m.\u001b[39madd(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mnormpath(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(root, file)))\n\u001b[1;32m     36\u001b[0m \u001b[39mfor\u001b[39;00m directory \u001b[39min\u001b[39;00m dirs:\n\u001b[1;32m     37\u001b[0m   \u001b[39m# Recursively search for files in subfolders\u001b[39;00m\n\u001b[1;32m     38\u001b[0m   search_files(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(root, directory))\n",
      "File \u001b[0;32m~/anaconda3/envs/ffcv/lib/python3.9/posixpath.py:363\u001b[0m, in \u001b[0;36mnormpath\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[39mif\u001b[39;00m (comp \u001b[39m!=\u001b[39m dotdot \u001b[39mor\u001b[39;00m (\u001b[39mnot\u001b[39;00m initial_slashes \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m new_comps) \u001b[39mor\u001b[39;00m\n\u001b[1;32m    362\u001b[0m      (new_comps \u001b[39mand\u001b[39;00m new_comps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m dotdot)):\n\u001b[0;32m--> 363\u001b[0m     new_comps\u001b[39m.\u001b[39;49mappend(comp)\n\u001b[1;32m    364\u001b[0m \u001b[39melif\u001b[39;00m new_comps:\n\u001b[1;32m    365\u001b[0m     new_comps\u001b[39m.\u001b[39mpop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\" Evaluate all models on the time-harmonic datasets\"\"\"\n",
    "import pprint\n",
    "from pathlib import Path\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "import ml_collections\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import os\n",
    "# from matplotlib import colors\n",
    "import torch\n",
    "from wavebench.dataloaders.helmholtz_loader import get_dataloaders_helmholtz\n",
    "import numpy as np\n",
    "\n",
    "from wavebench import wavebench_figure_path\n",
    "from wavebench.nn.pl_model_wrapper import LitModel\n",
    "from wavebench import wavebench_checkpoint_path\n",
    "from wavebench.plot_utils import plot_images, remove_frame\n",
    "\n",
    "\n",
    "\n",
    "all_models = [\n",
    "  {\n",
    "    \"tag\": 'fno-depth-4',\n",
    "    \"config.model_config/model_name\": 'fno',\n",
    "    \"config.model_config/num_hidden_layers\": 4\n",
    "  },\n",
    "  {\n",
    "    \"tag\": 'fno-depth-8',\n",
    "    \"config.model_config/model_name\": 'fno',\n",
    "    \"config.model_config/num_hidden_layers\": 8\n",
    "  },\n",
    "  {\n",
    "    \"tag\": 'unet-ch-32',\n",
    "    \"config.model_config/model_name\": 'unet',\n",
    "    \"config.model_config/channel_reduction_factor\": 2\n",
    "  },\n",
    "  {\n",
    "    \"tag\": 'unet-ch-64',\n",
    "    \"config.model_config/model_name\": 'unet',\n",
    "    \"config.model_config/channel_reduction_factor\": 1\n",
    "  },\n",
    "\n",
    "              ]\n",
    "\n",
    "\n",
    "# Initialize the W&B API client\n",
    "api = wandb.Api()\n",
    "\n",
    "\n",
    "pp = pprint.PrettyPrinter(depth=6)\n",
    "device = 'cpu'\n",
    "\n",
    "eval_config = ml_collections.ConfigDict()\n",
    "\n",
    "\n",
    "eval_config.visualize_real_prediction = True\n",
    "\n",
    "# problem setting: can be 'isotropic' or 'anisotropic'\n",
    "for eval_config.kernel_type in ['isotropic', 'anisotropic']:\n",
    "# for eval_config.kernel_type in ['anisotropic']:\n",
    "\n",
    "  # frequency: can be in [1.0, 1.5, 2.0, 4.0]\n",
    "  # for eval_config.frequency in [4.0]:\n",
    "  for eval_config.frequency in [1.0, 1.5, 2.0, 4.0]:\n",
    "    save_path = f\"{wavebench_figure_path}/time_harmonic/model_out_{eval_config.kernel_type}_{eval_config.frequency}\"\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "      os.makedirs(save_path)\n",
    "\n",
    "    test_loader = get_dataloaders_helmholtz(\n",
    "      eval_config.kernel_type,\n",
    "      eval_config.frequency)['test']\n",
    "    model_dict = {}\n",
    "\n",
    "    for model_filters in all_models:\n",
    "      _model_filters = model_filters.copy()\n",
    "\n",
    "      model_tag = _model_filters.pop('tag')\n",
    "\n",
    "      project = f'helmholtz_{eval_config.kernel_type}_{eval_config.frequency}'\n",
    "      runs = api.runs(\n",
    "        path=f\"tliu/{project}\",\n",
    "        filters=_model_filters)\n",
    "\n",
    "      # make sure that there is a unique model that satisfies the filters\n",
    "      assert len(runs) == 1\n",
    "\n",
    "      run_id = runs[0].id\n",
    "\n",
    "      checkpoint_reference = f\"tliu/{project}/model-{run_id}:best\"\n",
    "      print(f'checkpoint: {checkpoint_reference}')\n",
    "\n",
    "      # delete all the checkpoints that do not have the aliases such as 'best\n",
    "      artifact_versions = api.artifact_versions(\n",
    "        name=f'{project}/model-{run_id}', type_name='model')\n",
    "\n",
    "      for v in artifact_versions:\n",
    "        if len(v.aliases) == 0:\n",
    "          v.delete()\n",
    "          print(f'deleted {v.name}')\n",
    "        else:\n",
    "          print(f'kept {v.name}, {v.aliases}')\n",
    "\n",
    "      artifact_dir = WandbLogger.download_artifact(\n",
    "        artifact=checkpoint_reference,\n",
    "        save_dir=wavebench_checkpoint_path)\n",
    "\n",
    "      # load checkpoint\n",
    "      model = LitModel.load_from_checkpoint(\n",
    "        Path(artifact_dir) / \"model.ckpt\").to(device)\n",
    "\n",
    "      print('model hparams:')\n",
    "      pp.pprint(model.hparams.model_config)\n",
    "\n",
    "      model_dict[model_tag] = model\n",
    "\n",
    "    sample_input, sample_target = next(iter(test_loader))\n",
    "\n",
    "\n",
    "    # plot the predictions\n",
    "    pred_dict_real = {}\n",
    "    pred_dict_img = {}\n",
    "    pred_diff_dict_real = {}\n",
    "    pred_diff_dict_img = {}\n",
    "\n",
    "    for tag, model in model_dict.items():\n",
    "      pred = model(\n",
    "        sample_input.to(device)).detach().cpu().squeeze()\n",
    "      pred_dict_real[tag] = pred.squeeze()[0]\n",
    "      pred_dict_img[tag] = pred.squeeze()[1]\n",
    "      pred_diff_dict_real[tag] = ((\n",
    "        pred.squeeze()[0] - sample_target.squeeze()[0]).abs()\\\n",
    "          / torch.norm(sample_target.squeeze(), p=2))\n",
    "      pred_diff_dict_img[tag] = ((\n",
    "        pred.squeeze()[1] - sample_target.squeeze()[1]).abs()\\\n",
    "          / torch.norm(sample_target.squeeze(), p=2))\n",
    "\n",
    "    if eval_config.visualize_real_prediction:\n",
    "      pred_dict = pred_dict_real\n",
    "      pred_diff_dict = pred_diff_dict_real\n",
    "      sample_target_channel = sample_target.squeeze()[0]\n",
    "    else:\n",
    "      pred_dict = pred_dict_img\n",
    "      pred_diff_dict = pred_diff_dict_img\n",
    "      sample_target_channel = sample_target.squeeze()[1]\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(5.5, 5.5 * 3/4 )\n",
    "    ax = fig.subplots(3, 4)\n",
    "    im = np.empty(ax.shape, dtype=object)\n",
    "\n",
    "    # First row: plot the input and target\n",
    "    im[0,1] = ax[0,1].imshow(sample_input.squeeze(), cmap='coolwarm')\n",
    "    im[0,2] = ax[0,2].imshow(sample_target_channel, cmap='coolwarm')\n",
    "    ax[0,1].set_title('input')\n",
    "    if eval_config.visualize_real_prediction:\n",
    "      ax[0,2].set_title('targ real')\n",
    "    else:\n",
    "      ax[0,2].set_title('targ img')\n",
    "    cb = fig.colorbar(im[0, 1], ax=ax[0, :], pad=0.02, shrink=0.7)\n",
    "    cb.remove()\n",
    "\n",
    "    # Second row: plot the predictions\n",
    "    vrange_ = [min((x.min() for x in pred_dict.values() )), max(x.max() for x in pred_dict.values())]\n",
    "\n",
    "    for i, model_tag in enumerate(pred_dict.keys()):\n",
    "      im[1,i] = ax[1,i].imshow(\n",
    "        pred_dict[model_tag], cmap='coolwarm', vmin = vrange_[0], vmax = vrange_[1])\n",
    "      ax[1,i].set_title(model_tag)\n",
    "    fig.colorbar(im[1, -1], ax=ax[1, :], pad=0.02, shrink=0.7)\n",
    "\n",
    "    # Third row: plot the prediction differences\n",
    "    vrange_ = [min((x.min() for x in pred_diff_dict.values() )), max(x.max() for x in pred_diff_dict.values())]\n",
    "\n",
    "    for i, model_tag in enumerate(pred_diff_dict.keys()):\n",
    "      im[2,i] = ax[2,i].imshow(\n",
    "        pred_diff_dict[model_tag], cmap='Reds',\n",
    "        )\n",
    "    fig.colorbar(im[2, -1], ax=ax[2, :], pad=0.02, shrink=0.7)\n",
    "    [remove_frame(ax_) for ax_ in ax.flatten()]\n",
    "    plt.savefig(\n",
    "      f\"{save_path}/model_out_{eval_config.kernel_type}_{eval_config.frequency}.pdf\",\n",
    "      format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wave",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
