{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from bisect import bisect\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def to_numpy(x):\n",
    "  return x.detach().cpu().numpy()\n",
    "\n",
    "#files Loader\n",
    "def MyLoader(GL, do = \"train\", config = None, args=None):\n",
    "  if config is not None: \n",
    "    batch_size  = config['train']['batchsize']\n",
    "    workers = config['data']['load_workers']\n",
    "    database = config['Project']['database']\n",
    "    if database == 'GRF_7Hz': \n",
    "      size = 128\n",
    "    elif database in {'GRF_12Hz','GRF_15Hz'}: \n",
    "      size = 64\n",
    "  elif args is not None:  \n",
    "    batch_size = args.batchsize\n",
    "    workers = args.load_workers\n",
    "    database = args.database\n",
    "    if database == 'GRF_7Hz': \n",
    "      size = 128\n",
    "    elif database in {'GRF_12Hz', 'GRF_15Hz'}: \n",
    "      size = 64\n",
    "  else: \n",
    "    batch_size = 50\n",
    "    workers = 4\n",
    "\n",
    "\n",
    "  if do == 'train': \n",
    "    list_x_train, list_y_train = GL('train')\n",
    "    list_x_valid, list_y_valid = GL('validation')\n",
    "    Train_Data_set = File_Loader(list_x_train,list_y_train, size = size, data=database)\n",
    "    Valid_Data_set = File_Loader(list_x_valid,list_y_valid, size = size, data=database)\n",
    "    ##### setting the data Loader\n",
    "    train_loader = DataLoader(dataset = Train_Data_set, \n",
    "                         shuffle = True, \n",
    "                         batch_size = batch_size,\n",
    "                         num_workers= workers)\n",
    "\n",
    "    valid_loader = DataLoader(dataset = Valid_Data_set, \n",
    "                            shuffle = False, \n",
    "                            batch_size =batch_size,\n",
    "                            num_workers= workers)\n",
    "    return train_loader, valid_loader\n",
    "\n",
    "  elif do == 'test':\n",
    "    list_x_test, list_y_test = GL('test')\n",
    "    Test_Data_set = File_Loader(list_x_test, list_y_test, size = size, data=database)\n",
    "    ##### setting the data Loader\n",
    "    test_loader = DataLoader(dataset = Test_Data_set, \n",
    "                            shuffle = False, \n",
    "                            batch_size = batch_size,\n",
    "                            num_workers= workers)\n",
    "    return test_loader\n",
    "\n",
    "class GettingLists(object):\n",
    "  #Generating the list for train/valid/test--> each sample is 5000 velocity/data\n",
    "  def __init__(self, data_for_training, \n",
    "                    wave_eq = \"acoustic\",\n",
    "                    data_base = \"GRF_7Hz\", \n",
    "                    PATH = 'databases', \n",
    "                    batch_data_size = int(5000)):\n",
    "    super(GettingLists, self).__init__()\n",
    "    self.PATH = os.path.join(PATH, wave_eq, data_base)\n",
    "    self.batch_data = batch_data_size\n",
    "    valid_limit = data_for_training//self.batch_data \n",
    "    self.valid_limit = valid_limit\n",
    "    if data_base == 'GRF_7Hz': \n",
    "      self.end = int(6) \n",
    "    elif data_base in {'GRF_12Hz', 'GRF_15Hz'} :\n",
    "      self.end = int(10)\n",
    "   \n",
    "  def get_list(self, do):\n",
    "    if do == 'train':\n",
    "      in_limit_train  = np.array([os.path.join(self.PATH, \n",
    "                                                'model', \n",
    "                                                f'velocity{k}.npy') for k in \\\n",
    "                                                range(1,self.valid_limit+1)])\n",
    "      out_limit_train = np.array([os.path.join(self.PATH, \n",
    "                                                'data', \n",
    "                                                f'pressure{k}.npy')for k in \\\n",
    "                                                range(1,self.valid_limit+1)])\n",
    "      return in_limit_train, out_limit_train\n",
    "\n",
    "\n",
    "    elif do == 'validation':\n",
    "      in_limit_valid  = np.array([os.path.join(self.PATH, \n",
    "                                              'model', \n",
    "                                              f'velocity{k}.npy') for k in \\\n",
    "                                              range(self.end,self.end+1)])\n",
    "      out_limit_valid= np.array([os.path.join(self.PATH,\n",
    "                                              'data', \n",
    "                                              f'pressure{k}.npy') for k in \\\n",
    "                                              range(self.end,self.end+1)])\n",
    "      return  in_limit_valid, out_limit_valid\n",
    "\n",
    "    elif do =='test':\n",
    "      in_limit_test  = np.array([os.path.join(self.PATH,\n",
    "                                               'model', f'velocity{k}.npy') for k in \\\n",
    "                                                range(self.valid_limit+1, self.end+1)])\n",
    "      out_limit_test = np.array([os.path.join(self.PATH, \n",
    "                                                'data', f'pressure{k}.npy')for k in \\\n",
    "                                                range(self.valid_limit+1, self.end+1)])\n",
    "      return in_limit_test, out_limit_test\n",
    "  \n",
    "  def __call__(self, do = 'train'):\n",
    "    return self.get_list(do)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  PATH: \"databases\"\n",
    "  PDE_type: \"acoustic\"\n",
    "  process: 'GRF_12Hz'\n",
    "  n_sample: 25000\n",
    "  load_workers: 10\n",
    "  frequency: 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gl = GettingLists(\n",
    "  data_for_training=25000,\n",
    "  wave_eq = \"acoustic\",\n",
    "  data_base = \"GRF_12Hz\",\n",
    "  PATH = \"databases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_x_train, list_y_train = gl('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_x_test, list_y_test = gl('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['databases/acoustic/GRF_12Hz/data/pressure6.npy',\n",
       "       'databases/acoustic/GRF_12Hz/data/pressure7.npy',\n",
       "       'databases/acoustic/GRF_12Hz/data/pressure8.npy',\n",
       "       'databases/acoustic/GRF_12Hz/data/pressure9.npy',\n",
       "       'databases/acoustic/GRF_12Hz/data/pressure10.npy'], dtype='<U47')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(list_x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class File_Loader(Dataset):\n",
    "    #data loader file\n",
    "    def __init__(self, data_paths, target_paths, size =128, data = \"GRF\"):\n",
    "        self.size = size\n",
    "        self.data = data\n",
    "\n",
    "        if self.data == \"GRF_7Hz\":\n",
    "          self.data_memmaps = [np.load(path, mmap_mode='r') for path in data_paths]\n",
    "          self.target_memmaps = [np.load(path, mmap_mode='r') for path in target_paths]\n",
    "        elif self.data == (\"GRF_12Hz\") or (\"GRF_15Hz\") :\n",
    "          self.data_memmaps = [np.load(path, mmap_mode='r').view(float) for path in data_paths]\n",
    "          self.target_memmaps = [np.load(path, mmap_mode='r').view(float) for path in target_paths]\n",
    "        elif self.data == (\"GRF_12Hz_vz\") or (\"GRF_15Hz_vz\"):\n",
    "          self.data_memmaps = [np.load(path, mmap_mode='r').view(float) for path in data_paths]\n",
    "          self.target_memmaps = [np.load(path, mmap_mode='r').view(float).reshape(2,self.size,self.size,2) for path in target_paths]\n",
    "\n",
    "        self.start_indices = [0] * len(data_paths)\n",
    "        self.data_count = 0\n",
    "\n",
    "        for index, memmap in enumerate(self.data_memmaps):\n",
    "            self.start_indices[index] = self.data_count\n",
    "            self.data_count += memmap.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_count\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        memmap_index = bisect(self.start_indices, index) - 1\n",
    "        index_in_memmap = index - self.start_indices[memmap_index]\n",
    "        data = np.copy(self.data_memmaps[memmap_index][index_in_memmap])\n",
    "        target = np.copy(self.target_memmaps[memmap_index][index_in_memmap])\n",
    "        if self.data == \"GRF_7Hz\":\n",
    "          return torch.tensor(data*1e-3, dtype=torch.float).view(self.size,self.size,1), torch.tensor(target, dtype=torch.float).view(self.size,self.size,1)\n",
    "        elif self.data == (\"GRF_12Hz\") or (\"GRF_15Hz\"):\n",
    "          return torch.tensor(data*1e-3, dtype=torch.float).view(self.size,self.size,1), torch.tensor(target, dtype=torch.float).view(self.size,self.size,2)\n",
    "        elif self.data == (\"GRF_12Hz_vz\") or (\"GRF_15Hz_vz\"):\n",
    "          return torch.tensor(data*1e-3, dtype=torch.float).view(self.size,self.size,1), torch.tensor(target, dtype=torch.float).view(2,self.size,self.size,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "File_Loader(\n",
    "  data_paths=,\n",
    "  target_paths=\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wave",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
